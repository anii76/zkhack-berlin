<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="" />
    <link
      rel="stylesheet"
      as="style"
      onload="this.rel='stylesheet'"
      href="https://fonts.googleapis.com/css2?display=swap&amp;family=Inter%3Awght%40400%3B500%3B700%3B900&amp;family=Noto+Sans%3Awght%40400%3B500%3B700%3B900"
    />

    <title>Stitch Design</title>
    <link rel="icon" type="image/x-icon" href="data:image/x-icon;base64," />

    <script src="/face-api.js"></script>
    <script src="/js/commons.js"></script>
    <script src="/js/faceDetectionControls.js"></script>
    <script src="https://cdn.tailwindcss.com?plugins=forms,container-queries"></script>
    <style>
      .video-container { position: relative; width: 100%; }
      #inputVideo, #overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
    </style>
  </head>
  <body>
    <div class="relative flex size-full min-h-screen flex-col bg-slate-50 justify-between group/design-root overflow-x-hidden" style='font-family: Inter, "Noto Sans", sans-serif;'>
      <div>
        <div class="flex items-center bg-slate-50 p-4 pb-2 justify-between">
          <a href="/" class="text-[#0d141c] flex size-12 shrink-0 items-center" data-icon="ArrowLeft" data-size="24px" data-weight="regular">
            <svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" fill="currentColor" viewBox="0 0 256 256">
              <path d="M224,128a8,8,0,0,1-8,8H59.31l58.35,58.34a8,8,0,0,1-11.32,11.32l-72-72a8,8,0,0,1,0-11.32l72-72a8,8,0,0,1,11.32,11.32L59.31,120H216A8,8,0,0,1,224,128Z"></path>
            </svg>
          </a>
          <h2 class="text-[#0d141c] text-lg font-bold leading-tight tracking-[-0.015em] flex-1 text-center pr-12">Send Funds</h2>
        </div>
        <h3 class="text-[#0d141c] tracking-light text-2xl font-bold leading-tight px-4 text-center pb-2 pt-5">Capture Recipient's Face</h3>
        <p class="text-[#0d141c] text-base font-normal leading-normal pb-3 pt-1 px-4 text-center">
          Ensure the recipient's face is fully visible within the viewfinder for accurate recognition.
        </p>
        <div class="flex w-full grow bg-slate-50 @container p-4 justify-center">
          <div class="w-full max-w-xs gap-1 overflow-hidden bg-slate-50 @[480px]:gap-2 aspect-[2/3] rounded-lg flex items-center justify-center video-container relative" style="height: 320px; max-width: 100vw;">
            <video id="inputVideo" autoplay muted playsinline class="rounded-lg bg-black w-full h-full object-cover"></video>
            <canvas id="overlay" class="rounded-lg w-full h-full absolute top-0 left-0"></canvas>
            <img id="inputImage" class="rounded-lg bg-black w-full h-full object-cover absolute top-0 left-0 hidden" />
          </div>
        </div>
        <!-- Center the image upload component -->
        <div class="flex justify-center items-center mb-2">
          <input type="file" id="uploadPhoto" accept="image/*" disabled class="block w-full max-w-xs text-sm text-slate-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-blue-50 file:text-blue-700 hover:file:bg-blue-100" />
        </div>
        <div class="flex px-4 py-3 w-full max-w-md mx-auto">
          <button id="captureBtn"
            class="flex min-w-[84px] max-w-[480px] cursor-pointer items-center justify-center overflow-hidden rounded-lg h-12 px-5 flex-1 bg-[#0c7ff2] text-slate-50 text-base font-bold leading-normal tracking-[0.015em]"
            disabled
          >
            <span class="truncate">Capture Image</span>
          </button>
        </div>
        <div id="embeddings-container" class="hidden flex flex-col items-center justify-center py-6">
          <div class="text-blue-600 text-xl font-bold mb-2">Face Embeddings</div>
          <textarea id="embeddings-output" class="font-mono text-xs border rounded px-2 py-1 w-80 h-32" readonly></textarea>
          <button id="copy-embeddings" class="bg-[#0c7ff2] text-white rounded px-2 py-1 text-xs mt-2">Copy Embeddings</button>
          <div id="copy-embeddings-status" class="text-xs text-green-600 mt-1 hidden">Copied!</div>
        </div>
        <div id="claim-link-container" class="hidden flex flex-col items-center justify-center py-6">
          <div class="text-green-600 text-xl font-bold mb-2">Face captured!</div>
          <div class="text-[#0d141c] text-base font-normal mb-2">Share this link with the recipient to claim their funds:</div>
          <div class="flex items-center gap-2">
            <input id="claim-link" class="font-mono text-xs border rounded px-2 py-1 w-64" readonly />
            <button id="copy-link" class="bg-[#0c7ff2] text-white rounded px-2 py-1 text-xs">Copy</button>
          </div>
          <div id="copy-status" class="text-xs text-green-600 mt-1 hidden">Copied!</div>
        </div>
        <div id="face-status" class="text-center text-red-600 font-semibold"></div>
      </div>
      <div>
        <div class="flex gap-2 border-t border-[#e7edf4] bg-slate-50 px-4 pb-3 pt-2">
          <a class="just flex flex-1 flex-col items-center justify-end gap-1 rounded-full text-[#0d141c]" href="/">
            <div class="text-[#0d141c] flex h-8 items-center justify-center" data-icon="House" data-size="24px" data-weight="fill">
              <svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" fill="currentColor" viewBox="0 0 256 256">
                <path
                  d="M224,115.55V208a16,16,0,0,1-16,16H168a16,16,0,0,1-16-16V168a8,8,0,0,0-8-8H112a8,8,0,0,0-8,8v40a16,16,0,0,1-16,16H48a16,16,0,0,1-16-16V115.55a16,16,0,0,1,5.17-11.78l80-75.48.11-.11a16,16,0,0,1,21.53,0,1.14,1.14,0,0,0,.11.11l80,75.48A16,16,0,0,1,224,115.55Z"
                ></path>
              </svg>
            </div>
          </a>
          <a class="just flex flex-1 flex-col items-center justify-end gap-1 text-[#49739c]" href="/scan">
            <div class="text-[#49739c] flex h-8 items-center justify-center" data-icon="CreditCard" data-size="24px" data-weight="regular">
              <svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" fill="currentColor" viewBox="0 0 256 256">
                <path
                  d="M224,48H32A16,16,0,0,0,16,64V192a16,16,0,0,0,16,16H224a16,16,0,0,0,16-16V64A16,16,0,0,0,224,48Zm0,16V88H32V64Zm0,128H32V104H224v88Zm-16-24a8,8,0,0,1-8,8H168a8,8,0,0,1,0-16h32A8,8,0,0,1,208,168Zm-64,0a8,8,0,0,1-8,8H120a8,8,0,0,1,0-16h16A8,8,0,0,1,144,168Z"
                ></path>
              </svg>
            </div>
          </a>
          <a class="just flex flex-1 flex-col items-center justify-end gap-1 text-[#49739c]" href="/generating">
            <div class="text-[#49739c] flex h-8 items-center justify-center" data-icon="User" data-size="24px" data-weight="regular">
              <svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" fill="currentColor" viewBox="0 0 256 256">
                <path
                  d="M230.92,212c-15.23-26.33-38.7-45.21-66.09-54.16a72,72,0,1,0-73.66,0C63.78,166.78,40.31,185.66,25.08,212a8,8,0,1,0,13.85,8c18.84-32.56,52.14-52,89.07-52s70.23,19.44,89.07,52a8,8,0,1,0,13.85-8ZM72,96a56,56,0,1,1,56,56A56.06,56.06,0,0,1,72,96Z"
                ></path>
              </svg>
            </div>
          </a>
        </div>
        <div class="h-5 bg-slate-50"></div>
      </div>
    </div>
    <script>
      let stream;
      let isModelLoaded = false;
      async function startWebcam() {
        const videoEl = document.getElementById('inputVideo');
        try {
          // Use the front (selfie) camera by default
          stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
        } catch (err) {
          // fallback to any camera
          stream = await navigator.mediaDevices.getUserMedia({ video: true });
        }
        videoEl.srcObject = stream;
      }
      async function loadModels() {
        await faceapi.nets.tinyFaceDetector.load('/models/');
        await faceapi.nets.faceRecognitionNet.load('/models/');
        isModelLoaded = true;
        document.getElementById('uploadPhoto').disabled = false;
        document.getElementById('captureBtn').disabled = false;
      }
      async function detectFace(sourceType = 'video') {
        const canvas = document.getElementById('overlay');
        let input, displaySize;
        if (sourceType === 'image') {
          input = document.getElementById('inputImage');
          displaySize = { width: input.naturalWidth, height: input.naturalHeight };
        } else {
          input = document.getElementById('inputVideo');
          displaySize = { width: input.videoWidth, height: input.videoHeight };
        }
        faceapi.matchDimensions(canvas, displaySize);
        const detection = await faceapi.detectSingleFace(input, new faceapi.TinyFaceDetectorOptions());
        const resizedDetections = detection ? faceapi.resizeResults(detection, displaySize) : null;
        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        if (resizedDetections) {
          faceapi.draw.drawDetections(canvas, resizedDetections);
        }
        return detection;
      }
      // Helper function to check if an image is loaded (from face-api.js isMediaLoaded)
      function isImageLoaded(img) {
        return img.complete;
      }
      document.addEventListener('DOMContentLoaded', async () => {
        await loadModels();
        await startWebcam();
        const inputImage = document.getElementById('inputImage');
        const inputVideo = document.getElementById('inputVideo');
        document.getElementById('uploadPhoto').addEventListener('change', async function(e) {
          const file = e.target.files[0];
          if (!file) return;
          const url = URL.createObjectURL(file);
          inputImage.src = url;
          inputImage.onload = async () => {
            inputImage.classList.remove('hidden');
            inputVideo.classList.add('hidden');
            if (!isImageLoaded(inputImage)) {
              console.warn('Uploaded image is not fully loaded, skipping detection.');
              return;
            }
            const detection = await detectFace('image');
            const status = document.getElementById('face-status');
            if (detection) {
              status.textContent = '';
              document.getElementById('captureBtn').style.display = 'none';
              const descriptor = await faceapi.computeFaceDescriptor(inputImage);
              const embeddingsContainer = document.getElementById('embeddings-container');
              const embeddingsOutput = document.getElementById('embeddings-output');
              if (embeddingsOutput && embeddingsContainer) {
                embeddingsOutput.value = JSON.stringify(Array.from(descriptor), null, 2);
                embeddingsContainer.classList.remove('hidden');
                const copyBtn = document.getElementById('copy-embeddings');
                const copyStatus = document.getElementById('copy-embeddings-status');
                if (copyBtn && copyStatus) {
                  copyBtn.onclick = function() {
                    navigator.clipboard.writeText(embeddingsOutput.value);
                    copyStatus.classList.remove('hidden');
                    setTimeout(() => copyStatus.classList.add('hidden'), 1200);
                  };
                }
              } else {
                console.warn('Embeddings output or container not found in DOM');
              }
            } else {
              status.textContent = 'No face detected in uploaded photo. Try another image.';
              inputImage.classList.add('hidden');
              inputVideo.classList.remove('hidden');
            }
          };
        });
        document.getElementById('captureBtn').onclick = async () => {
          if (!isModelLoaded) return;
          let detection;
          if (!inputImage.classList.contains('hidden')) {
            detection = await detectFace('image');
          } else {
            detection = await detectFace('video');
          }
          const status = document.getElementById('face-status');
          if (detection) {
            status.textContent = '';
            document.getElementById('captureBtn').style.display = 'none';
            let descriptor;
            if (!inputImage.classList.contains('hidden')) {
              descriptor = await faceapi.computeFaceDescriptor(inputImage);
            } else {
              descriptor = await faceapi.computeFaceDescriptor(inputVideo);
            }
            const embeddingsContainer = document.getElementById('embeddings-container');
            const embeddingsOutput = document.getElementById('embeddings-output');
            if (embeddingsOutput && embeddingsContainer) {
              embeddingsOutput.value = JSON.stringify(Array.from(descriptor), null, 2);
              embeddingsContainer.classList.remove('hidden');
              const copyBtn = document.getElementById('copy-embeddings');
              const copyStatus = document.getElementById('copy-embeddings-status');
              if (copyBtn && copyStatus) {
                copyBtn.onclick = function() {
                  navigator.clipboard.writeText(embeddingsOutput.value);
                  copyStatus.classList.remove('hidden');
                  setTimeout(() => copyStatus.classList.add('hidden'), 1200);
                };
              }
            } else {
              console.warn('Embeddings output or container not found in DOM');
            }
            if (stream && inputImage.classList.contains('hidden')) stream.getTracks().forEach(t => t.stop());
          } else {
            status.textContent = 'No face detected. Try again.';
          }
        };
      });
    </script>
  </body>
</html> 