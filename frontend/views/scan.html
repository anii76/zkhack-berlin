<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin />
    <link rel="stylesheet" as="style" onload="this.rel='stylesheet'" href="https://fonts.googleapis.com/css2?display=swap&family=Inter:wght@400;500;700;900&family=Noto+Sans:wght@400;500;700;900" />
    <title>Send Funds - ZK FacePay</title>
    <link rel="icon" type="image/x-icon" href="data:image/x-icon;base64," />
    <script src="/face-api.js"></script>
    <script src="/js/commons.js"></script>
    <script src="/js/faceDetectionControls.js"></script>
    <script src="https://cdn.tailwindcss.com?plugins=forms,container-queries"></script>
    <style>.video-container { position: relative; width: 100%; } #inputVideo, #overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>
  </head>
  <body>
    <div class="min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 flex items-center justify-center p-4" style='font-family: Inter, "Noto Sans", sans-serif;'>
      <div class="w-full max-w-md">
        <button onclick="window.location.href='/'" class="flex items-center text-white mb-4 gap-2 hover:text-purple-300 transition-colors" style="background: none; border: none;">
          <svg xmlns="http://www.w3.org/2000/svg" class="w-4 h-4" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7" /></svg>
          Back
        </button>
        <div class="bg-white/10 backdrop-blur-lg border border-white/20 rounded-2xl shadow-lg p-8">
          <h2 class="text-white text-2xl font-bold text-center mb-2">Send Funds</h2>
          <h3 class="text-white text-xl font-semibold text-center mb-3">Capture Recipient's Face</h3>
          <p class="text-slate-300 text-base text-center mb-6">Ensure the recipient's face is fully visible within the viewfinder for accurate recognition.</p>
          <div class="flex w-full grow justify-center mb-4">
            <div class="w-full max-w-xs aspect-[2/3] rounded-lg flex items-center justify-center video-container relative" style="height: 320px; max-width: 100vw;">
              <video id="inputVideo" autoplay muted playsinline class="rounded-lg bg-black w-full h-full object-cover"></video>
              <canvas id="overlay" class="rounded-lg w-full h-full absolute top-0 left-0"></canvas>
              <img id="inputImage" class="rounded-lg bg-black w-full h-full object-cover absolute top-0 left-0 hidden" />
            </div>
          </div>
          <div class="flex justify-center items-center mb-2">
            <input type="file" id="uploadPhoto" accept="image/*" disabled class="block w-full max-w-xs text-sm text-slate-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-blue-50 file:text-blue-700 hover:file:bg-blue-100" />
          </div>
          <div class="flex w-full">
            <button id="captureBtn" class="w-full rounded-lg h-12 bg-gradient-to-r from-blue-500 to-purple-500 hover:from-blue-600 hover:to-purple-600 text-white text-base font-bold transition-colors" disabled>
              Capture Image
            </button>
          </div>
          <div id="embeddings-container" class="hidden flex flex-col items-center justify-center py-6">
            <div class="text-blue-400 text-xl font-bold mb-2">Face Embeddings</div>
            <textarea id="embeddings-output" class="font-mono text-xs border rounded px-2 py-1 w-80 h-32" readonly></textarea>
            <button id="copy-embeddings" class="bg-gradient-to-r from-blue-500 to-purple-500 text-white rounded px-2 py-1 text-xs mt-2">Copy Embeddings</button>
            <div id="copy-embeddings-status" class="text-xs text-green-400 mt-1 hidden">Copied!</div>
          </div>
          <div id="claim-link-container" class="hidden flex flex-col items-center justify-center py-6">
            <div class="text-green-400 text-xl font-bold mb-2">Face captured!</div>
            <div class="text-white text-base font-normal mb-2">Share this link with the recipient to claim their funds:</div>
            <div class="flex items-center gap-2">
              <input id="claim-link" class="font-mono text-xs border rounded px-2 py-1 w-64 bg-white/10 border-white/20 text-white" readonly />
              <button id="copy-link" class="bg-gradient-to-r from-blue-500 to-purple-500 text-white rounded px-2 py-1 text-xs">Copy</button>
            </div>
            <div id="copy-status" class="text-xs text-green-400 mt-1 hidden">Copied!</div>
          </div>
          <div id="face-status" class="text-center text-red-400 font-semibold"></div>
        </div>
      </div>
    </div>
    <script>
      let stream;
      let isModelLoaded = false;
      async function startWebcam() {
        const videoEl = document.getElementById('inputVideo');
        try {
          // Use the front (selfie) camera by default
          stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
        } catch (err) {
          // fallback to any camera
          stream = await navigator.mediaDevices.getUserMedia({ video: true });
        }
        videoEl.srcObject = stream;
      }
      async function loadModels() {
        await faceapi.nets.tinyFaceDetector.load('/models/');
        await faceapi.nets.faceRecognitionNet.load('/models/');
        isModelLoaded = true;
        document.getElementById('uploadPhoto').disabled = false;
        document.getElementById('captureBtn').disabled = false;
      }
      async function detectFace(sourceType = 'video') {
        const canvas = document.getElementById('overlay');
        let input, displaySize;
        if (sourceType === 'image') {
          input = document.getElementById('inputImage');
          displaySize = { width: input.naturalWidth, height: input.naturalHeight };
        } else {
          input = document.getElementById('inputVideo');
          displaySize = { width: input.videoWidth, height: input.videoHeight };
        }
        faceapi.matchDimensions(canvas, displaySize);
        const detection = await faceapi.detectSingleFace(input, new faceapi.TinyFaceDetectorOptions());
        const resizedDetections = detection ? faceapi.resizeResults(detection, displaySize) : null;
        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
        if (resizedDetections) {
          faceapi.draw.drawDetections(canvas, resizedDetections);
        }
        return detection;
      }
      // Helper function to check if an image is loaded (from face-api.js isMediaLoaded)
      function isImageLoaded(img) {
        return img.complete;
      }
      document.addEventListener('DOMContentLoaded', async () => {
        await loadModels();
        await startWebcam();
        const inputImage = document.getElementById('inputImage');
        const inputVideo = document.getElementById('inputVideo');
        document.getElementById('uploadPhoto').addEventListener('change', async function(e) {
          const file = e.target.files[0];
          if (!file) return;
          const url = URL.createObjectURL(file);
          inputImage.src = url;
          inputImage.onload = async () => {
            inputImage.classList.remove('hidden');
            inputVideo.classList.add('hidden');
            if (!isImageLoaded(inputImage)) {
              console.warn('Uploaded image is not fully loaded, skipping detection.');
              return;
            }
            const detection = await detectFace('image');
            const status = document.getElementById('face-status');
            if (detection) {
              status.textContent = '';
              document.getElementById('captureBtn').style.display = 'none';
              const descriptor = await faceapi.computeFaceDescriptor(inputImage);
              const embeddingsContainer = document.getElementById('embeddings-container');
              const embeddingsOutput = document.getElementById('embeddings-output');
              if (embeddingsOutput && embeddingsContainer) {
                embeddingsOutput.value = JSON.stringify(Array.from(descriptor), null, 2);
                embeddingsContainer.classList.remove('hidden');
                const copyBtn = document.getElementById('copy-embeddings');
                const copyStatus = document.getElementById('copy-embeddings-status');
                if (copyBtn && copyStatus) {
                  copyBtn.onclick = function() {
                    navigator.clipboard.writeText(embeddingsOutput.value);
                    copyStatus.classList.remove('hidden');
                    setTimeout(() => copyStatus.classList.add('hidden'), 1200);
                  };
                }
              } else {
                console.warn('Embeddings output or container not found in DOM');
              }
            } else {
              status.textContent = 'No face detected in uploaded photo. Try another image.';
              inputImage.classList.add('hidden');
              inputVideo.classList.remove('hidden');
            }
          };
        });
        document.getElementById('captureBtn').onclick = async () => {
          if (!isModelLoaded) return;
          let detection;
          if (!inputImage.classList.contains('hidden')) {
            detection = await detectFace('image');
          } else {
            detection = await detectFace('video');
          }
          const status = document.getElementById('face-status');
          if (detection) {
            status.textContent = '';
            document.getElementById('captureBtn').style.display = 'none';
            let descriptor;
            if (!inputImage.classList.contains('hidden')) {
              descriptor = await faceapi.computeFaceDescriptor(inputImage);
            } else {
              descriptor = await faceapi.computeFaceDescriptor(inputVideo);
            }
            const embeddingsContainer = document.getElementById('embeddings-container');
            const embeddingsOutput = document.getElementById('embeddings-output');
            if (embeddingsOutput && embeddingsContainer) {
              embeddingsOutput.value = JSON.stringify(Array.from(descriptor), null, 2);
              embeddingsContainer.classList.remove('hidden');
              const copyBtn = document.getElementById('copy-embeddings');
              const copyStatus = document.getElementById('copy-embeddings-status');
              if (copyBtn && copyStatus) {
                copyBtn.onclick = function() {
                  navigator.clipboard.writeText(embeddingsOutput.value);
                  copyStatus.classList.remove('hidden');
                  setTimeout(() => copyStatus.classList.add('hidden'), 1200);
                };
              }
            } else {
              console.warn('Embeddings output or container not found in DOM');
            }
            if (stream && inputImage.classList.contains('hidden')) stream.getTracks().forEach(t => t.stop());
          } else {
            status.textContent = 'No face detected. Try again.';
          }
        };
      });
    </script>
  </body>
</html> 